{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exercises"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8c9062ef0a30e1b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. You can use SGD or mini-batch GD for a large number of features. Additionally, if the training set doesn't have many instances, you can also use regular batch GD.\n",
    "2. Gradient Descent will have a hard time converging to the global minimum if features are not standardized, unlike the normal equation or SVD. You can utilize a `StandardScaler()`\n",
    "3. No, the cost function for Logistic Regression is convex, so you can eventually find the global min\n",
    "4. For batch, you can converge to the global min. For mini-batch and SGD, the algorithm will often walk around the global min so you must use other techniques to correct this like a learning schedule\n",
    "5. If the training error remains stable and lower, then that means the model is overfitting the training set and you need to use a regularization technique\n",
    "6. No, it could be that in non-linear models (like polynomial) it needs to escape a local minima\n",
    "7. SGD because there is an update at every training instance. Batch, however, can actually converge unlike the other two which walk around the global min. The other two can eventually converge if using regularization or a learning schedule\n",
    "8. When there is a gap in the learning curve, it means the model has overfit the training data. To solve this you can: add more training instances, regularize the model, or decrease polynomial degrees in the transformer\n",
    "9. The model has a high bias. To reduce it you should increase alpha, which is a hyperparameter that controls how much to regularize a model\n",
    "10. a) Reduce the chance of overfitting the model b) If you want to select fewer features for the model to use c) Lasso by itself can be erratic if there are more features than training instances or if several features are highly correlated\n",
    "11. 2 logistic regression classifiers since the problem is solved using 2 binary classifiers. The problem could also be framed as multi output but softmax applies to multilabel problems (i.e., selecting 1 of k classes)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "872429cf78fb478b"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T06:49:37.852381Z",
     "start_time": "2025-04-15T06:49:37.606925Z"
    }
   },
   "id": "7a3c2fd1c36cb180"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3e54e15022ffa137"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n0                  5.1               3.5                1.4               0.2\n1                  4.9               3.0                1.4               0.2\n2                  4.7               3.2                1.3               0.2\n3                  4.6               3.1                1.5               0.2\n4                  5.0               3.6                1.4               0.2\n..                 ...               ...                ...               ...\n145                6.7               3.0                5.2               2.3\n146                6.3               2.5                5.0               1.9\n147                6.5               3.0                5.2               2.0\n148                6.2               3.4                5.4               2.3\n149                5.9               3.0                5.1               1.8\n\n[150 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>6.7</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.3</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>5.0</td>\n      <td>1.9</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>6.5</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>6.2</td>\n      <td>3.4</td>\n      <td>5.4</td>\n      <td>2.3</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>5.9</td>\n      <td>3.0</td>\n      <td>5.1</td>\n      <td>1.8</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "\n",
    "iris.data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-11T00:41:02.161824Z",
     "start_time": "2025-04-11T00:40:51.559991Z"
    }
   },
   "id": "7c650e3b6c92172f"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y = iris[\"target\"].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T17:36:28.692127Z",
     "start_time": "2025-04-15T17:36:28.675553Z"
    }
   },
   "id": "d1d915d7bd850adb"
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "X_with_bias = np.c_[np.ones(len(X)), X]\n",
    "\n",
    "total_size = len(X_with_bias)\n",
    "valid_size, test_size = int(total_size * 0.2), int(total_size * 0.2)\n",
    "train_size = total_size - valid_size - test_size\n",
    "\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(total_size)\n",
    "\n",
    "X_train = X_with_bias[indices[: train_size]]\n",
    "y_train = y[indices[:train_size]]\n",
    "X_valid = X_with_bias[indices[train_size : train_size+valid_size]]\n",
    "y_valid = y[indices[train_size : train_size+valid_size]]\n",
    "X_test = X_with_bias[indices[train_size+valid_size : total_size]]\n",
    "y_test = y[indices[train_size+valid_size : total_size]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T17:45:10.376459Z",
     "start_time": "2025-04-15T17:45:10.372482Z"
    }
   },
   "id": "979c599c5c31c160"
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "assert (train_size + valid_size + test_size) == total_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T17:45:17.321954Z",
     "start_time": "2025-04-15T17:45:17.312638Z"
    }
   },
   "id": "be1a8531d18c9067"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "# one-hot encode output\n",
    "# alternative is to use pd.get_dummies() function\n",
    "\n",
    "def to_one_hot(a):\n",
    "    b = np.zeros((a.size, a.max() + 1), dtype=np.int64)\n",
    "    b[np.arange(a.size), a] = 1\n",
    "    \n",
    "    return b\n",
    "\n",
    "\n",
    "\n",
    "Y_train_one_hot = to_one_hot(y_train)\n",
    "Y_valid_one_hot = to_one_hot(y_valid)\n",
    "Y_test_one_hot = to_one_hot(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T19:22:08.107523Z",
     "start_time": "2025-04-15T19:22:08.104004Z"
    }
   },
   "id": "a1e870911e5bfd8a"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "# Standardize input\n",
    "mean = X_train[:, 1:].mean(axis=0)\n",
    "std = X_train[:, 1:].std(axis=0)\n",
    "\n",
    "X_train[:, 1:] = (X_train[:, 1:] - mean) / std\n",
    "X_valid[:, 1:] = (X_valid[:, 1:] - mean) / std\n",
    "X_test[:, 1:] = (X_test[:, 1:] - mean) / std"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T19:32:40.781394Z",
     "start_time": "2025-04-15T19:32:40.778293Z"
    }
   },
   "id": "770000ae0be6ed3d"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "def softmax(logits):\n",
    "    exps = np.exp(logits)\n",
    "    exp_sums = exps.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    return exps / exp_sums"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T19:44:26.165065Z",
     "start_time": "2025-04-15T19:44:26.156902Z"
    }
   },
   "id": "fc5de2e8b59e0708"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.7085808486476917\n",
      "1000 0.14519367480830644\n",
      "2000 0.1301309575504088\n",
      "3000 0.12009639326384539\n",
      "4000 0.11372961364786884\n",
      "5000 0.11002459532472425\n"
     ]
    }
   ],
   "source": [
    "# batch gradient descent using a softmax algorithm and utilizing early stopping\n",
    "# BGD: controlled by # of epochs and learning rate\n",
    "# early stopping: when validation error is at its lowest\n",
    "m, n = len(X_train), len(X_train[0])\n",
    "k = len(np.unique(y_train)) # number of classes\n",
    "learn_rate, n_epochs = 0.5, 5001\n",
    "epsilon = 1e-5\n",
    "\n",
    "np.random.seed(42)\n",
    "Theta = np.random.randn(n, k)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    Y_proba = softmax(X_train @ Theta)\n",
    "    if epoch % 1000 == 0:\n",
    "        Y_proba_valid = softmax(X_valid @ Theta)\n",
    "        xentropy_losses = -(Y_valid_one_hot * np.log(Y_proba_valid + epsilon))\n",
    "        print(epoch, xentropy_losses.sum(axis=1).mean())\n",
    "        \n",
    "    error = Y_proba - Y_train_one_hot\n",
    "    gradients = 1 / m * X_train.T @ error\n",
    "    Theta = Theta - learn_rate * gradients"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T20:40:25.544060Z",
     "start_time": "2025-04-15T20:40:25.491021Z"
    }
   },
   "id": "41c1eb3b153a2b05"
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "np.float64(0.9333333333333333)"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = X_valid @ Theta\n",
    "Y_proba = softmax(logits)\n",
    "y_predict = Y_proba.argmax(axis=1)\n",
    "\n",
    "accuracy_score = (y_predict == y_valid).mean()\n",
    "accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T20:44:58.952668Z",
     "start_time": "2025-04-15T20:44:58.946272Z"
    }
   },
   "id": "c99eed310c26bbaa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
